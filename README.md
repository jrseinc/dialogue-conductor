# Dialogue Conductor

Dialogue Conductor is a data processing pipeline designed to parse, chunk, and index media subtitles into a Pinecone vector database. It utilizes OpenAI's embedding models for semantic search (dense vectors) and a locally trained BM25 model for keyword search (sparse vectors), enabling powerful hybrid search capabilities over movie and television dialogue.

## Features

- **Subtitle Parsing & Chunking:** Reads `.srt` files, handles encoding fallbacks, and groups dialogue lines into logical overlapping chunks.
- **Automated Metadata Extraction:** Uses regular expressions to extract clean titles, seasons, and episode numbers directly from standardized media filenames.
- **Hybrid Search Ready:** Generates dense embeddings via OpenAI (`text-embedding-3-small`) and sparse vectors via `pinecone-text` (BM25) for highly accurate search retrieval.
- **Automated Database Management:** Includes scripts to provision serverless Pinecone indexes and batch-upload processed text chunks.

## Prerequisites

- Python 3.10 or higher
- An active [OpenAI API](https://platform.openai.com/) account and API key.
- An active [Pinecone](https://www.pinecone.io/) account and API key.

## Directory Structure

Before running the scripts, ensure your working directory contains the appropriate media folders. The scripts expect the following structure:

```text
dialogue-conductor/
├── movies/                 # Place movie subfolders here
│   └── Inception/
│       └── Inception.1080p.srt
├── shows/                  # Place TV series subfolders here
│   └── Breaking Bad/
│       ├── Breaking.Bad.S01E01.srt
│       └── Breaking.Bad.S01E02.srt
├── bm25_dataset/           # Autogenerated during BM25 training
├── main.py
├── pinecone_service.py
├── pyproject.toml
├── setup_db.py
└── train_bm25.py
```

## Setup and Installation

**1. Clone the repository and navigate to the directory**
Navigate to the root directory where your `pyproject.toml` is located.

**2. Create and activate a virtual environment (Recommended)**
For Windows:

```bash
python -m venv venv
venv\Scripts\activate
```

For macOS/Linux:

```bash
python -m venv venv
source venv/bin/activate
```

**3. Install dependencies**
You can install the project and its dependencies directly using pip:

```bash
pip install .
```

**4. Configure Environment Variables**
Create a `.env` file in the root directory and add your API keys:

```env
OPENAI_API_KEY="your_openai_api_key_here"
PINECONE_API_KEY="your_pinecone_api_key_here"
PINECONE_INDEX_NAME="dialogue-detective"
```

## Usage Pipeline

Processing your media requires running the pipeline in three distinct steps:

### Step 1: Initialize the Database

Run the setup script to provision your Pinecone Serverless index. This will create the index (if it does not already exist) using the `dotproduct` metric and a dimension of 1536.

```bash
python setup_db.py
```

### Step 2: Train the BM25 Models

Before uploading, the system needs to train a BM25 model on your specific subtitle corpuses to generate accurate sparse vectors. Ensure your `.srt` files are organized in the `shows/` and `movies/` directories.

```bash
python train_bm25.py
```

_Note: This will generate a `bm25_model.json` file inside the `bm25_dataset/<media_name>/` folder for each processed title._

### Step 3: Process and Upload

Run the main orchestrator to chunk the subtitles, generate dense embeddings via OpenAI, encode sparse vectors via the trained BM25 model, and upsert everything into Pinecone.

```bash
python main.py
```
